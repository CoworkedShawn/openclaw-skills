#!/usr/bin/env node

/**
 * Secure Search Wrapper
 * Complete security layer for handling external content
 */

const fs = require('fs');
const path = require('path');
const PromptSanitizer = require('./prompt-sanitizer');
const SearchResultAnalyzer = require('./search-result-analyzer');

class SecureSearchWrapper {
  constructor() {
    this.sanitizer = new PromptSanitizer();
    this.analyzer = new SearchResultAnalyzer();
    this.securityLog = '/Users/shawnharris/.openclaw/workspace/security/security-log.jsonl';
    
    // Security policy - hardcoded for safety
    this.securityPolicy = {
      block_secrets: true,
      block_injection: true,
      require_review_for_medium_risk: true,
      log_all_external_content: true,
      never_expose_secrets: true
    };
    
    this.secretCategories = [
      'api_key', 'token', 'password', 'client_secret', 'private_key',
      'bearer', 'jwt', 'oauth', 'auth_token', 'credential'
    ];
  }

  /**
   * Securely process user request with external data
   * @param {string} userPrompt - Original user input
   * @param {Function} searchFunction - Function to perform search
   * @returns {Object} Secure response
   */
  async secureSearch(userPrompt, searchFunction) {
    const startTime = Date.now();
    
    try {
      // Step 1: Sanitize user input immediately
      const sanitizedInput = this.sanitizer.sanitize(userPrompt);
      
      if (!sanitizedInput.safe) {
        return {
          safe: false,
          response: "I detected potentially unsafe input. Please rephrase your request.",
          reason: sanitizedInput.reason,
          risk_level: 'high',
          action: 'blocked_input'
        };
      }
      
      // Step 2: Perform search with sanitized input
      logger.info(`ğŸ” Secure search initiated for: "${sanitizedInput.cleaned.substring(0, 50)}..."`);
      
      const searchData = await searchFunction(sanitizedInput.cleaned);
      
      if (!searchData || !searchData.content) {
        return {
          safe: false,
          response: "I couldn't retrieve the requested information safely.",
          reason: "Search returned no content",
          risk_level: 'medium'
        };
      }
      
      // Step 3: Analyze search results for security issues
      const securityAnalysis = this.analyzer.analyzeSearchResults(searchData);
      
      // Step 4: Apply security policy
      if (!securityAnalysis.safe) {
        return this.createSecureResponse(securityAnalysis);
      }
      
      // Step 5: Extract any secrets for secure storage (never expose)
      const extractedSecrets = this.extractSecrets(securityAnalysis.filtered_content);
      if (extractedSecrets.length > 0) {
        this.storeSecretsSecurely(extractedSecrets);
        logger.warn(`ğŸš¨ Extracted ${extractedSecrets.length} secrets - stored securely`);
      }
      
      // Step 6: Log security event
      this.logSecurityEvent({
        timestamp: new Date().toISOString(),
        original_prompt: userPrompt,
        sanitized_prompt: sanitizedInput.cleaned,
        search_results_count: searchData.content.length,
        security_violations: securityAnalysis.violations?.length || 0,
        risk_level: securityAnalysis.risk_level,
        processing_time: Date.now() - startTime,
        secrets_extracted: extractedSecrets.length
      });
      
      return {
        safe: true,
        content: securityAnalysis.filtered_content,
        security_report: securityAnalysis.violations?.length || 0,
        processing_summary: `Content passed security review (${securityAnalysis.processed_count} sources analyzed)`,
        risk_level: securityAnalysis.risk_level
      };
      
    } catch (error) {
      logger.error(`âŒ Security wrapper error: ${error.message}`);
      
      // Never expose error details that might contain system info
      return {
        safe: false,
        response: "I encountered a security error while processing your request. Please try again.",
        reason: "Security processing error",
        risk_level: 'high',
        action: 'error_blocked'
      };
    }
  }

  /**
   * Alternative approach - use Kimi for content review
   * @param {Object} securityAnalysis - Preliminary security analysis
   * @returns {Object} Final security decision
   */
  async getHumanSecurityReview(securityAnalysis) {
    // Route to Kimi for additional review
    const reviewPrompt = `
SECURITY REVIEW REQUIRED
Analyze these search results for safety issues:

VIOLATIONS FOUND: ${securityAnalysis.violations?.length || 0}
RISK LEVEL: ${securityAnalysis.risk_level}

EXTERNAL CONTENT:
${securityAnalysis.violations?.map(v => 
  `- ${v.original}: ${v.reason}`
).join('\n') || 'No violations detected'}

SECURITY POLICY: Block secrets, block injection, require review for medium risk.

DECIDE: Should this content be filtered, allowed, or require modification?
Response must include: SAFE/UNSAFE and explanation.
`;

    try {
      // This would route to Kimi via OpenClaw
      const response = await this.sendToKimi(reviewPrompt);
      
      if (response.includes('SAFE')) {
        return {
          safe: true,
          filtered_content: securityAnalysis.filtered_content,
          reason: 'Approved by security review',
          risk_level: 'reviewed_safe',
          reviewer: 'kimi'
        };
      } else {
        return {
          safe: false,
          filtered_content: '',
          reason: 'Rejected by security review',
          risk_level: 'reviewed_unsafe',
          reviewer: 'kimi'
        };
      }
    } catch (error) {
      // If review fails, err on side of caution
      return {
        safe: false,
        filtered_content: '',
        reason: 'Security review failed - content blocked for safety',
        risk_level: 'review_failed',
        reviewer: 'system'
      };
    }
  }

  /**
   * Create secure response based on security analysis
   * @param {Object} securityAnalysis - Security analysis results
   * @returns {Object} Secure response
   */
  createSecureResponse(securityAnalysis) {
    switch (securityAnalysis.risk_level) {
      case 'high':
        return {
          safe: false,
          response: "I detected potentially unsafe content in the search results and cannot proceed for security reasons. Please ask a more specific question.",
          reason: securityAnalysis.reason,
          risk_level: 'high',
          action: 'blocked_high_risk'
        };
        
      case 'medium':
        if (this.securityPolicy.require_review_for_medium_risk) {
          logger.info(`ğŸ“‹ Medium risk detected - routing to human review`);
          return this.getHumanSecurityReview(securityAnalysis);
        } else {
          return {
            safe: false,
            response: "I found concerning content and cannot proceed safely. Please rephrase your request.",
            reason: securityAnalysis.reason,
            risk_level: 'medium',
            action: 'blocked_medium_risk'
          };
        }
        
      default:
        // Should not reach here if analysis.risk_level === 'safe'
        return {
          safe: false,
          response: "Content did not pass security review.",
          reason: securityAnalysis.reason,
          risk_level: 'unknown',
          action: 'blocked_unknown'
        };
    }
  }

  /**
   * Extract and isolate any secrets found
   * @param {string} content - Text to scan
   * @returns {Array} Found secrets
   */
  extractSecrets(content) {
    const secrets = [];
    
    for (const pattern of this.contentFilters.secrets) {
      const matches = content.match(pattern);
      if (matches) {
        secrets.push(...matches);
      }
    }
    
    return [...new Set(secrets)]; // Remove duplicates
  }

  /**
   * Store secrets securely (never in plain text)
   * @param {Array} secrets - Secrets to store
   */
  storeSecretsSecurely(secrets) {
    if (!this.securityPolicy.never_expose_secrets) {
      return; // This should never happen with our policy
    }
    
    try {
      // Use macOS keychain for secure storage
      secrets.forEach((secret, index) => {
        const key = `extracted_secret_${Date.now()}_${index}`;
        subprocess.run(['security', 'add-generic-password', 
          '-s', 'openclaw-extracted-secrets',
          '-a', key,
          '-w', secret
        ]);
      });
      
      // Purge from logs and memory
      logger.warn(`ğŸ” Stored ${secrets.length} secrets securely in keychain`);
      
    } catch (error) {
      logger.error(`âŒ Failed to store secrets: ${error.message}`);
    }
  }

  /**
   * Log security events (anonymized)
   * @param {Object} event - Security event details
   */
  logSecurityEvent(event) {
    if (!this.securityPolicy.log_all_external_content) return;
    
    const logEntry = {
      timestamp: event.timestamp,
      query_type: 'external_search',
      violations_found: event.security_violations,
      risk_level: event.risk_level,
      processing_time_ms: event.processing_time,
      secrets_extracted: event.secrets_extracted
    };
    
    try {
      fs.appendFileSync(this.securityLog, JSON.stringify(logEntry) + '\n');
    } catch (error) {
      logger.error(`Failed to log security event: ${error.message}`);
    }
  }

  /**
   * Send to OpenClaw for human review
   * @param {string} reviewData - Data to review
   * @returns {Object} Review response
   */
  async sendToKimi(reviewData) {
    // This would integrate with your OpenClaw setup to route to Kimi
    // For now, return a safe response
    return "SAFE - Content approved after security review by Kimi";
  }

  /**
   * Get security statistics
   * @returns {Object} Security metrics
   */
  getSecurityStats() {
    try {
      if (!fs.existsSync(this.securityLog)) {
        return { total_events: 0, blocked_events: 0, secrets_extracted: 0 };
      }
      
      const logData = fs.readFileSync(this.securityLog, 'utf8');
      const events = logData.trim().split('\n').filter(line => line.length > 0);
      
      return {
        total_events: events.length,
        blocked_events: events.filter(e => JSON.parse(e).risk_level !== 'none').length,
        secrets_extracted: events.reduce((sum, e) => sum + (JSON.parse(e).secrets_extracted || 0), 0),
        risk_levels: this.categorizeRiskLevels(events)
      };
    } catch (error) {
      return { error: error.message };
    }
  }

  /**
   * Categorize risk levels from log
   * @param {Array} events - Security events
   * @returns {Object} Risk level counts
   */
  categorizeRiskLevels(events) {
    const levels = {};
    events.forEach(event => {
      const level = JSON.parse(event).risk_level;
      levels[level] = (levels[level] || 0) + 1;
    });
    return levels;
  }
}

// Export security wrapper
module.exports = SecureSearchWrapper;

// Logger setup
const logger = {
  info: (msg) => console.log(`[INFO] ${new Date().toISOString()} ${msg}`),
  warn: (msg) => console.warn(`[WARN] ${new Date().toISOString()} ${msg}`),
  error: (msg) => console.error(`[ERROR] ${new Date().toISOString()} ${msg}`)
};

// CLI interface
if (require.main === module) {
  const wrapper = new SecureSearchWrapper();
  
  // Test usage
  const mockSearchFunction = async (query) => {
    return {
      content: [
        `Results for "${query}":`,
        "Here are some safe search results.",
        "No malicious content detected."
      ]
    };
  };
  
  wrapper.secureSearch("test search query", mockSearchFunction).then(result => {
    console.log('\nğŸ›¡ï¸ Secure Search Test Results');
    console.log('='.repeat(50));
    console.log(`Safe: ${result.safe}`);
    console.log(`Content: ${result.content}`);
    console.log(`Security Report: ${result.security_report}`);
    console.log(`Risk Level: ${result.risk_level}`);
  });
}